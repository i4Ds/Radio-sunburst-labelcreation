{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join(os.path.abspath(os.sep), 'var', 'lib', 'ecallisto')\n",
    "URL_BASE = 'http://soleil.i4ds.ch/solarradio/data/2002-20yy_Callisto/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fetch_content(url):\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def extract_content(soup, substrings_to_include, substring_to_exclude):\n",
    "    \"\"\"\n",
    "    Extracts all the content from the given soup object based on the given parameters\n",
    "    substrings_to_include: If specified, only links with the given substrings will be extracted\n",
    "    substrings_to_exclude: If specified, links with the given substrings will be excluded\n",
    "    \n",
    "    Returns a list of all the links\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for link in soup.find_all('a'):\n",
    "        if all([pattern in link.get('href') for pattern in substrings_to_include]): # If all of the substrings are in the link\n",
    "            if not any([pattern in link.get('href') for pattern in substring_to_exclude]): # If none of the substrings are in the link\n",
    "                content.append(link.get('href'))\n",
    "    return content\n",
    "\n",
    "def extract_fit_gz_files(url, instrument, substrings_to_include=None, substring_to_exclude=None):\n",
    "    \"\"\"\n",
    "    Extracts all the .fit.gz files from the given url\n",
    "    instrument: If specified, only files with the instrument name will be extracted\n",
    "    substrings_to_include: If specified, only files with the given substrings will be extracted\n",
    "    substring_to_excluce: If specified, files with the given substrings will be excluded\n",
    "    \n",
    "    Returns a list of all the .fit.gz files\n",
    "    \"\"\"\n",
    "    soup = fetch_content(url)\n",
    "    if substrings_to_include is None:\n",
    "        substrings_to_include = ['.fit.gz']\n",
    "    if substring_to_exclude is None:\n",
    "        substring_to_exclude = []\n",
    "    if instrument:\n",
    "        substrings_to_include.append(instrument)\n",
    "    return extract_content(soup, substrings_to_include = substrings_to_include, substring_to_exclude=substring_to_exclude)\n",
    "\n",
    "def extract_fiz_gz_files_urls(year, month, day, instrument):\n",
    "    \"\"\"\n",
    "    Extracts all the .fit.gz files from the given year, month and day\n",
    "    instrument: If specified, only files with the instrument name will be extracted\n",
    "    \n",
    "    Returns a list of all the .fit.gz files\n",
    "    \"\"\"\n",
    "    url = f'{URL_BASE}{year}/{month}/{day}/'\n",
    "    file_names = extract_fit_gz_files(url, instrument=instrument)\n",
    "    urls = [url + file_name for file_name in file_names]\n",
    "    return urls\n",
    "\n",
    "def download_ecallisto_file(URL, return_download_path=False, root=ROOT_DIR):\n",
    "    # Split URL to get the file name and add the directory\n",
    "    year, month, day, filename = URL.split('/')[-4:]\n",
    "    directory = os.path.join(root, year, month, day)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if not os.path.exists(file_path) or os.path.getsize(file_path) < 2000: # Check that it is not an empty file (e.g. 404 error)\n",
    "        # Downloading the file by sending the request to the URL\n",
    "        req = requests.get(URL)\n",
    "        with open(file_path,'wb') as output_file:\n",
    "            output_file.write(req.content)\n",
    "    # Return path (e.g. for astropy.io.fits.open)\n",
    "    if return_download_path:\n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = extract_fiz_gz_files_urls('2023', '01', '01', instrument='ALASKA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_START = datetime(2023, 1, 1, 14, 0, 0)\n",
    "DOWNLOAD_END = datetime(2023, 1, 2, 17, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ecallisto_files(start_date=datetime.now().date() - timedelta(days=1), end_date=datetime.today().date(), instrument='ALASKA'):\n",
    "    \"\"\"\n",
    "    Downloads all the eCallisto files from the given start date to the end date.\n",
    "    \"\"\"\n",
    "    assert start_date < end_date, 'Start date should be less than end date and both should be datetime objects'\n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        for month in range(start_date.month, end_date.month + 1):\n",
    "            month = f'0{month}' if month < 10 else month\n",
    "            for day in range(start_date.day, end_date.day + 1):\n",
    "                day = f'0{day}' if day < 10 else day\n",
    "                urls = extract_fiz_gz_files_urls(year, month, day, instrument=instrument)\n",
    "                for url in tqdm(urls, desc=f'Downloading {year}-{month}-{day}'):\n",
    "                    download_ecallisto_file(url, return_download_path=False)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2023-01-24: 100%|██████████| 239/239 [00:00<00:00, 118114.61it/s]\n",
      "Downloading 2023-01-25: 100%|██████████| 11/11 [00:00<00:00, 33825.03it/s]\n"
     ]
    }
   ],
   "source": [
    "download_ecallisto_files(instrument='ALASKA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunflare_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75b4b533ce743184e2e2cd8cec81140adf5f35d71c59667a5fcd80c861828eff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
